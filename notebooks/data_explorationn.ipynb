{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6654939f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f32d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")  # run only once\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUESTIONS_PATH = \"../data/raw/Questions.csv\"\n",
    "ANSWERS_PATH = \"../data/raw/Answers.csv\"\n",
    "TAGS_PATH = \"../data/raw/Tags.csv\"\n",
    "\n",
    "QUESTIONS_OUTPUT_PATH = \"../data/processed/questions_clean.csv\"\n",
    "ANSWERS_OUTPUT_PATH = \"../data/processed/answers_clean.csv\"\n",
    "\n",
    "CHUNK_SIZE = 50000  # rows processed at a time(large so chunckwise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c9622",
   "metadata": {},
   "source": [
    "counting questions/answers/tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "question_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(ANSWERS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "answer_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e13e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(TAGS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "tag_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad31fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_summary = pd.DataFrame({\n",
    "    \"TYpe\": [\"Questions\", \"Answers\", \"Tags\"],\n",
    "    \"Count\": [question_count, answer_count, tag_count]\n",
    "})\n",
    "\n",
    "dataset_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_ques= pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "# sample_df_ques.head()\n",
    "sample_df_ques[['Title','Body']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72136158",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ef3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_ques= pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "sample_df_ques.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import XMLParsedAsHTMLWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress XML warning once\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db98f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_pipeline(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Decode HTML entities (e.g., &lt; â†’ <)\n",
    "    text = html.unescape(text)\n",
    "    try:\n",
    "        # Remove HTML/XML tags\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "\n",
    "    # Normalize multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Join back\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66108dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cleaning on Small Subset\n",
    "test_df = pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=10000\n",
    ")\n",
    "\n",
    "test_df[\"raw_text\"] = (\n",
    "    test_df[\"Title\"].fillna(\"\") + \" \" +\n",
    "    test_df[\"Body\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "test_df[\"clean_text\"] = test_df[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "sample = test_df[[\"raw_text\", \"clean_text\"]].iloc[0]\n",
    "\n",
    "print(\"RAW TEXT:\\n\", sample[\"raw_text\"][:500])\n",
    "print(\"\\nCLEAN TEXT:\\n\", sample[\"clean_text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dataset Cleaning (Chunk Processing)\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    chunksize=CHUNK_SIZE\n",
    "):\n",
    "\n",
    "    # Combine title and body\n",
    "    chunk[\"raw_text\"] = (\n",
    "        chunk[\"Title\"].fillna(\"\") + \" \" +\n",
    "        chunk[\"Body\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    chunk[\"clean_text\"] = chunk[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    processed_chunk = chunk[[\"Id\", \"Score\", \"clean_text\"]]\n",
    "\n",
    "    # Write incrementally\n",
    "    processed_chunk.to_csv(\n",
    "        QUESTIONS_OUTPUT_PATH,\n",
    "        mode=\"w\" if first_chunk else \"a\",\n",
    "        header=first_chunk,\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    first_chunk = False\n",
    "\n",
    "print(\" Full preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d137241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "clean_df_sample = pd.read_csv(QUESTIONS_OUTPUT_PATH, nrows=5)\n",
    "\n",
    "clean_df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "clean_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_OUTPUT_PATH, chunksize=100000)\n",
    ")\n",
    "\n",
    "print(\"Original rows:\", original_count)\n",
    "print(\"Cleaned rows:\", clean_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463a7d4",
   "metadata": {},
   "source": [
    "answers cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4403828",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_ans= pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "# sample_df_ans.head()\n",
    "sample_df_ques[['Body']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd008de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cleaning on Small Subset of ans\n",
    "test_df_ans = pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=10000\n",
    ")\n",
    "\n",
    "test_df_ans[\"raw_text\"] = (\n",
    "    test_df_ans[\"Body\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "test_df_ans[\"clean_text\"] = test_df_ans[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "sample = test_df_ans[[\"raw_text\", \"clean_text\"]].iloc[0]\n",
    "\n",
    "print(\"RAW TEXT:\\n\", sample[\"raw_text\"][:500])\n",
    "print(\"\\nCLEAN TEXT:\\n\", sample[\"clean_text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a18138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dataset Cleaning (Chunk Processing)\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    chunksize=CHUNK_SIZE\n",
    "):\n",
    "\n",
    "    # Combine title and body\n",
    "    chunk[\"raw_text\"] = (\n",
    "        chunk[\"Body\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    chunk[\"clean_text\"] = chunk[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    processed_chunk = chunk[[\"Id\", \"Score\", \"clean_text\"]]\n",
    "\n",
    "    # Write incrementally\n",
    "    processed_chunk.to_csv(\n",
    "        ANSWERS_OUTPUT_PATH,\n",
    "        mode=\"w\" if first_chunk else \"a\",\n",
    "        header=first_chunk,\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    first_chunk = False\n",
    "\n",
    "print(\" Full preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "clean_df_sample = pd.read_csv(QUESTIONS_OUTPUT_PATH, nrows=5)\n",
    "\n",
    "clean_df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZATION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "# Load cleaned questions\n",
    "clean_df = pd.read_csv(\"../data/processed/questions_clean.csv\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1,2),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "tfidf_questions = vectorizer.fit_transform(clean_df[\"clean_text\"].fillna(\"\"))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(vectorizer, \"../data/processed/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Questions TF-IDF Shape:\", tfidf_questions.shape)\n",
    "\n",
    "# Save sparse matrix\n",
    "save_npz(\"../data/processed/questions_tfidf.npz\", tfidf_questions)\n",
    "\n",
    "print(\"Questions TF-IDF saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load cleaned answers\n",
    "clean_answers = pd.read_csv(\"../data/processed/answers_clean.csv\")\n",
    "\n",
    "# Load saved vectorizer\n",
    "vectorizer = joblib.load(\"../data/processed/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Transform answers (DO NOT FIT AGAIN)\n",
    "tfidf_answers = vectorizer.transform(clean_answers[\"clean_text\"].fillna(\"\"))\n",
    "\n",
    "print(\"Answers TF-IDF Shape:\", tfidf_answers.shape)\n",
    "\n",
    "# Save sparse matrix\n",
    "save_npz(\"../data/processed/answers_tfidf.npz\", tfidf_answers)\n",
    "\n",
    "print(\"Answers TF-IDF saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
